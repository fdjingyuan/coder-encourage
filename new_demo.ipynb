{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hzy/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# /usr/bin/python3\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import time\n",
    "import random\n",
    "import traceback\n",
    "from model import predict, image_to_tensor, deepnn\n",
    "\n",
    "CASC_PATH = './data/haarcascade_files/haarcascade_frontalface_default.xml'\n",
    "cascade_classifier = cv2.CascadeClassifier(CASC_PATH)\n",
    "EMOTIONS = ['angry', 'disgusted', 'fearful', 'happy', 'sad', 'surprised', 'neutral']\n",
    "\n",
    "\n",
    "def format_image(image):\n",
    "    if len(image.shape) > 2 and image.shape[2] == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = cascade_classifier.detectMultiScale(\n",
    "        image,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=5\n",
    "    )\n",
    "    # None is no face found in image\n",
    "    if not len(faces) > 0:\n",
    "        return None, None\n",
    "    max_are_face = faces[0]\n",
    "    for face in faces:\n",
    "        if face[2] * face[3] > max_are_face[2] * max_are_face[3]:\n",
    "            max_are_face = face\n",
    "    # face to image\n",
    "    face_coor = max_are_face\n",
    "    image = image[face_coor[1]:(face_coor[1] + face_coor[2]), face_coor[0]:(face_coor[0] + face_coor[3])]\n",
    "    # Resize image to network size\n",
    "    try:\n",
    "        image = cv2.resize(image, (48, 48), interpolation=cv2.INTER_CUBIC)\n",
    "    except Exception:\n",
    "        print(\"[+} Problem during resize\")\n",
    "        return None, None\n",
    "    return image, face_coor\n",
    "\n",
    "\n",
    "def face_dect(image):\n",
    "    \"\"\"\n",
    "    Detecting faces in image\n",
    "    :param image: \n",
    "    :return:  the coordinate of max face\n",
    "    \"\"\"\n",
    "    if len(image.shape) > 2 and image.shape[2] == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = cascade_classifier.detectMultiScale(\n",
    "        image,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=5\n",
    "    )\n",
    "    if not len(faces) > 0:\n",
    "        return None\n",
    "    max_face = faces[0]\n",
    "    for face in faces:\n",
    "        if face[2] * face[3] > max_face[2] * max_face[3]:\n",
    "            max_face = face\n",
    "    face_image = image[max_face[1]:(max_face[1] + max_face[2]), max_face[0]:(max_face[0] + max_face[3])]\n",
    "    try:\n",
    "        image = cv2.resize(face_image, (48, 48), interpolation=cv2.INTER_CUBIC) / 255.\n",
    "    except Exception:\n",
    "        print(\"[+} Problem during resize\")\n",
    "        return None\n",
    "    return face_image\n",
    "\n",
    "\n",
    "def resize_image(image, size):\n",
    "    try:\n",
    "        image = cv2.resize(image, size, interpolation=cv2.INTER_CUBIC) / 255.\n",
    "    except Exception:\n",
    "        print(\"+} Problem during resize\")\n",
    "        return None\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_emotion():\n",
    "    pass\n",
    "\n",
    "modelPath = './ckpt/'\n",
    "showBox = True\n",
    "tf.reset_default_graph()\n",
    "\n",
    "face_x = tf.placeholder(tf.float32, [None, 2304])\n",
    "y_conv = deepnn(face_x)\n",
    "probs = tf.nn.softmax(y_conv)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "ckpt = tf.train.get_checkpoint_state(modelPath)\n",
    "sess = tf.Session()\n",
    "if ckpt and ckpt.model_checkpoint_path:\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    print('Restore model sucsses!!\\nNOTE: Press SPACE on keyboard to capture face.')\n",
    "\n",
    "\n",
    "\n",
    "##### 从这里开始是我的代码 ###########\n",
    "# 'angry', 'disgusted', 'fearful', 'happy', 'sad', 'surprised', 'neutral'\n",
    "# emoji_list和text_list结构差不多，都是一个map\n",
    "# label -> list，从预测的类别号到一个list，显示的时候会随机从list里面挑一个显示\n",
    "\n",
    "emoji_list = {}\n",
    "for index, emotion in enumerate(EMOTIONS):\n",
    "    tmp = []\n",
    "    for i in range(1, 4):\n",
    "        tmp.append(cv2.imread('./data/emojis/' + emotion + str(i) + '.jpg', -1))\n",
    "    emoji_list[index] = tmp\n",
    "\n",
    "text_list = {\n",
    "    0 : [\n",
    "        'It\\'s ok.'\n",
    "        'You are not debugging alone.',\n",
    "        'Everyone gets angry sometimes.',\n",
    "    ],\n",
    "    1: ['Test'],\n",
    "    2: ['Test'],\n",
    "    3: [\n",
    "        'Seems like coding can sometimes be fun.',\n",
    "        'Happy coding.',\n",
    "        'While many coders are still in sadness, glad you are not like them.',\n",
    "        'Finished another feature?',\n",
    "    ],\n",
    "    4: [\n",
    "        'Cheer up, your program will finally work one day.',\n",
    "        'You haven\\'t type True as Ture have you?',\n",
    "        'Cheer up!',\n",
    "        'Have a break.',\n",
    "    ],\n",
    "    5: ['Test'],\n",
    "    6: ['Neutral Emotion'],\n",
    "}\n",
    "\n",
    "def random_choose(list_):\n",
    "    '''\n",
    "    随机从列表里面挑一个\n",
    "    '''\n",
    "    i = random.randint(0, len(list_) - 1)\n",
    "    return list_[i]\n",
    "\n",
    "class Parser(object):\n",
    "    \n",
    "    def __init__(self, emoji_list, text_list, showBox=True, parseEverySecond=1):\n",
    "        '''\n",
    "        emoji_list: emoji的label->list映射\n",
    "        text_list: text的label->list映射\n",
    "        showBox：是否显示人脸框\n",
    "        parseEverySecond：每多少秒处理一次图片。这个值越小，图片文字变化速度越快，同时对性能要求就越高\n",
    "        '''\n",
    "        self.showBox = True\n",
    "        self.previous_second = 0\n",
    "        self.emoji_list = emoji_list\n",
    "        self.text_list = text_list\n",
    "        self.text_to_show = None\n",
    "        self.emoji_to_show = None\n",
    "        self.parseEverySecond = parseEverySecond\n",
    "    \n",
    "    def parse_face(self, frame):\n",
    "        '''\n",
    "        检测人脸。如果showBox = True就标注人脸。返回检测到的人脸区域。\n",
    "        '''\n",
    "        detected_face, face_coor = format_image(frame)\n",
    "        if self.showBox:\n",
    "            if face_coor is not None:\n",
    "                [x, y, w, h] = face_coor\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2) \n",
    "        if face_coor is None:\n",
    "            return None\n",
    "        else:\n",
    "            return detected_face\n",
    "    \n",
    "    def predict_emotion(self, detected_face):\n",
    "        '''\n",
    "        预测表情，返回一个形状为(7, )的向量\n",
    "        '''\n",
    "        tensor = image_to_tensor(detected_face)\n",
    "        result = sess.run(probs, feed_dict={face_x: tensor})\n",
    "        return result\n",
    "    \n",
    "    def draw_emoji(self, frame):\n",
    "        '''\n",
    "        画 self.emoji_to_show 里面的表情\n",
    "        '''\n",
    "        if self.emoji_to_show is not None:\n",
    "            for c in range(0, 3):\n",
    "                frame[200:320, 10:130, c] = self.emoji_to_show[:, :, c] * (self.emoji_to_show[:, :, c] / 255.0) + \\\n",
    "                    frame[200:320, 10:130, c] * (1.0 - self.emoji_to_show[:, :, c] / 255.0)\n",
    "    \n",
    "    def draw_text(self, frame):\n",
    "        '''\n",
    "        画 self.text_to_show 里面的文字\n",
    "        '''\n",
    "        if self.text_to_show is not None:\n",
    "            cv2.putText(frame, self.text_to_show, (10, 350), cv2.FONT_HERSHEY_PLAIN, 1.5, (255, 0, 0), 2)\n",
    "\n",
    "    def parse(self, frame):\n",
    "        '''\n",
    "        主处理函数\n",
    "        '''\n",
    "        detected_face = self.parse_face(frame)\n",
    "        # 如果和上一次处理间隔大于self.parseEverySecond秒，就进行处理\n",
    "        if time.time() - self.previous_second > self.parseEverySecond:\n",
    "            # 如果有人脸则调用情绪分类模型\n",
    "            if detected_face is not None:\n",
    "                emotion_prob = self.predict_emotion(detected_face)\n",
    "                prob_index = np.argmax(emotion_prob[0])\n",
    "                # 随机选emoji和text\n",
    "                self.emoji_to_show = random_choose(self.emoji_list[prob_index])\n",
    "                self.text_to_show = random_choose(self.text_list[prob_index])\n",
    "            # 记录当前处理时间\n",
    "            self.previous_second = time.time()\n",
    "        \n",
    "        # 画出emoji和text\n",
    "        self.draw_emoji(frame)\n",
    "        self.draw_text(frame)\n",
    "\n",
    "video_captor = cv2.VideoCapture(0)\n",
    "parser = Parser(emoji_list, text_list, parseEverySecond=2)\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = video_captor.read()\n",
    "        # 处理图片\n",
    "        parser.parse(frame)\n",
    "        # 显示图片\n",
    "        cv2.imshow('face', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    video_captor.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = './ckpt/'\n",
    "showBox = True\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./ckpt/emotion_model-30001\n",
      "Restore model sucsses!!\n",
      "NOTE: Press SPACE on keyboard to capture face.\n"
     ]
    }
   ],
   "source": [
    "face_x = tf.placeholder(tf.float32, [None, 2304])\n",
    "y_conv = deepnn(face_x)\n",
    "probs = tf.nn.softmax(y_conv)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "ckpt = tf.train.get_checkpoint_state(modelPath)\n",
    "sess = tf.Session()\n",
    "if ckpt and ckpt.model_checkpoint_path:\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    print('Restore model sucsses!!\\nNOTE: Press SPACE on keyboard to capture face.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 从这里开始是我的代码 ###########\n",
    "# 'angry', 'disgusted', 'fearful', 'happy', 'sad', 'surprised', 'neutral'\n",
    "# emoji_list和text_list结构差不多，都是一个map\n",
    "# label -> list，从预测的类别号到一个list，显示的时候会随机从list里面挑一个显示\n",
    "\n",
    "emoji_list = {}\n",
    "for index, emotion in enumerate(EMOTIONS):\n",
    "    tmp = []\n",
    "    for i in range(1, 4):\n",
    "        tmp.append(cv2.imread('./data/emojis/' + emotion + str(i) + '.jpg', -1))\n",
    "    emoji_list[index] = tmp\n",
    "\n",
    "text_list = {\n",
    "    0 : [\n",
    "        'It\\'s ok.'\n",
    "        'You are not debugging alone.',\n",
    "        'Everyone gets angry sometimes.',\n",
    "    ],\n",
    "    1: ['Test'],\n",
    "    2: ['Test'],\n",
    "    3: [\n",
    "        'Seems like coding can sometimes be fun.',\n",
    "        'Happy coding.',\n",
    "        'While many coders are still in sadness, glad you are not like them.',\n",
    "        'Finished another feature?',\n",
    "    ],\n",
    "    4: [\n",
    "        'Cheer up, your program will finally work one day.',\n",
    "        'You haven\\'t type True as Ture have you?',\n",
    "        'Cheer up!',\n",
    "        'Have a break.',\n",
    "    ],\n",
    "    5: ['Test'],\n",
    "    6: ['Neutral Emotion'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_choose(list_):\n",
    "    '''\n",
    "    随机从列表里面挑一个\n",
    "    '''\n",
    "    i = random.randint(0, len(list_) - 1)\n",
    "    return list_[i]\n",
    "\n",
    "class Parser(object):\n",
    "    \n",
    "    def __init__(self, emoji_list, text_list, showBox=True, parseEverySecond=1):\n",
    "        '''\n",
    "        emoji_list: emoji的label->list映射\n",
    "        text_list: text的label->list映射\n",
    "        showBox：是否显示人脸框\n",
    "        parseEverySecond：每多少秒处理一次图片。这个值越小，图片文字变化速度越快，同时对性能要求就越高\n",
    "        '''\n",
    "        self.showBox = True\n",
    "        self.previous_second = 0\n",
    "        self.emoji_list = emoji_list\n",
    "        self.text_list = text_list\n",
    "        self.text_to_show = None\n",
    "        self.emoji_to_show = None\n",
    "        self.parseEverySecond = parseEverySecond\n",
    "    \n",
    "    def parse_face(self, frame):\n",
    "        '''\n",
    "        检测人脸。如果showBox = True就标注人脸。返回检测到的人脸区域。\n",
    "        '''\n",
    "        detected_face, face_coor = format_image(frame)\n",
    "        if self.showBox:\n",
    "            if face_coor is not None:\n",
    "                [x, y, w, h] = face_coor\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2) \n",
    "        if face_coor is None:\n",
    "            return None\n",
    "        else:\n",
    "            return detected_face\n",
    "    \n",
    "    def predict_emotion(self, detected_face):\n",
    "        '''\n",
    "        预测表情，返回一个形状为(7, )的向量\n",
    "        '''\n",
    "        tensor = image_to_tensor(detected_face)\n",
    "        result = sess.run(probs, feed_dict={face_x: tensor})\n",
    "        return result\n",
    "    \n",
    "    def draw_emoji(self, frame):\n",
    "        '''\n",
    "        画 self.emoji_to_show 里面的表情\n",
    "        '''\n",
    "        if self.emoji_to_show is not None:\n",
    "            for c in range(0, 3):\n",
    "                frame[200:320, 10:130, c] = self.emoji_to_show[:, :, c] * (self.emoji_to_show[:, :, c] / 255.0) + \\\n",
    "                    frame[200:320, 10:130, c] * (1.0 - self.emoji_to_show[:, :, c] / 255.0)\n",
    "    \n",
    "    def draw_text(self, frame):\n",
    "        '''\n",
    "        画 self.text_to_show 里面的文字\n",
    "        '''\n",
    "        if self.text_to_show is not None:\n",
    "            cv2.putText(frame, self.text_to_show, (10, 350), cv2.FONT_HERSHEY_PLAIN, 1.5, (255, 0, 0), 2)\n",
    "\n",
    "    def parse(self, frame):\n",
    "        '''\n",
    "        主处理函数\n",
    "        '''\n",
    "        detected_face = self.parse_face(frame)\n",
    "        # 如果和上一次处理间隔大于self.parseEverySecond秒，就进行处理\n",
    "        if time.time() - self.previous_second > self.parseEverySecond:\n",
    "            # 如果有人脸则调用情绪分类模型\n",
    "            if detected_face is not None:\n",
    "                emotion_prob = self.predict_emotion(detected_face)\n",
    "                prob_index = np.argmax(emotion_prob[0])\n",
    "                # 随机选emoji和text\n",
    "                self.emoji_to_show = random_choose(self.emoji_list[prob_index])\n",
    "                self.text_to_show = random_choose(self.text_list[prob_index])\n",
    "            # 记录当前处理时间\n",
    "            self.previous_second = time.time()\n",
    "        \n",
    "        # 画出emoji和text\n",
    "        self.draw_emoji(frame)\n",
    "        self.draw_text(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_captor = cv2.VideoCapture(0)\n",
    "parser = Parser(emoji_list, text_list, parseEverySecond=2)\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = video_captor.read()\n",
    "        # 处理图片\n",
    "        parser.parse(frame)\n",
    "        # 显示图片\n",
    "        cv2.imshow('face', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    video_captor.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
