{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import IPython.display as ipd\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "from glob import glob\n",
    "from scipy import signal\n",
    "import random\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_audio(filename=None, sr=1600, second=3, samples=None):\n",
    "    samples, sample_rate = librosa.load(filename, sr=sr)\n",
    "    \n",
    "    if second is not None and len(samples) < sr * second:\n",
    "        samples = np.pad(samples, (0, sr * second - len(samples)), 'constant')\n",
    "    if second is not None and len(samples) > sr * second:\n",
    "        samples = samples[0:sr * second]\n",
    "    return samples\n",
    "\n",
    "\n",
    "def mel_feature(sample,normalization=False, resize=None):\n",
    "    spectrogram = librosa.feature.melspectrogram(sample, sr=1600, n_mels=40, hop_length=160, n_fft=480, fmin=20, fmax=4000)\n",
    "    spectrogram = librosa.power_to_db(spectrogram)\n",
    "    spectrogram = spectrogram.astype(np.float32)\n",
    "    if normalization:\n",
    "        spectrogram = spectrogram.spectrogram()\n",
    "        spectrogram -= spectrogram\n",
    "    if resize:\n",
    "        spectrogram = cv2.resize(spectrogram, (resize, resize))\n",
    "    return spectrogram\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def plot_specgram(sample, window_size=20, step_size=10, eps=1e-10):\n",
    "    def log_specgram(audio, sample_rate = 1600, window_size=20,\n",
    "                     step_size=10, eps=1e-10):\n",
    "        nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "        noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "        freqs, times, spec = signal.spectrogram(audio,\n",
    "                                                fs=sample_rate,\n",
    "                                                window='hann',\n",
    "                                                nperseg=nperseg,\n",
    "                                                noverlap=noverlap\n",
    "                                                )\n",
    "        return freqs, times, np.log(spec.T.astype(np.float32) + eps)\n",
    "\n",
    "    freqs, times, spectrogram = log_specgram(sample)\n",
    "\n",
    "    fig = plt.figure(figsize=(14, 8))\n",
    "    ax1 = fig.add_subplot(211)\n",
    "    ax1.set_title('Raw wave')\n",
    "    ax1.set_ylabel('Amplitude')\n",
    "    ax1.plot(np.linspace(0, self.sr / len(self.samples), self.sr), self.samples)\n",
    "\n",
    "    ax2 = fig.add_subplot(212)\n",
    "    ax2.imshow(spectrogram.T, aspect='auto', origin='lower',\n",
    "               extent=[times.min(), times.max(), freqs.min(), freqs.max()])\n",
    "    ax2.set_yticks(freqs[::16])\n",
    "    ax2.set_xticks(times[::16])\n",
    "    ax2.set_title('Spectrogram')\n",
    "    ax2.set_ylabel('Freqs in Hz')\n",
    "    ax2.set_xlabel('Seconds')\n",
    "\"\"\"\n",
    "\n",
    "def play(sample):\n",
    "    return ipd.Audio(sample, 1600, autoplay=True)\n",
    "\n",
    "def timeshift(wav, sr=1600, ms=100):\n",
    "    shift = (sr * ms) // 1000\n",
    "    shift = random.randint(-shift, shift)\n",
    "    a = -min(0, shift)\n",
    "    b = max(0, shift)\n",
    "    data = np.pad(wav, (a, b), \"constant\")\n",
    "    return data[:len(data) - a] if a else data[b:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = os.listdir('./voice/')\n",
    "audios = [(load_audio('./voice/' + f, 1600), f[:-5]) for f in files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00225449,  0.00589441,  0.00647261, ..., -0.00945333,\n",
       "       -0.00452255,  0.00032612], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audios[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\librosa\\filters.py:284: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn('Empty filters detected in mel frequency basis. '\n"
     ]
    }
   ],
   "source": [
    "mel_features = [(mel_feature(audio[0]),audio[1]) for audio in audios]\n",
    "#plot_specgram(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 31)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel_features[2][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606.21063\n",
      "291.127\n"
     ]
    }
   ],
   "source": [
    "a = mel_features[1][0]\n",
    "b = mel_features[2][0]\n",
    "c = mel_features[8][0]\n",
    "dist1 = np.linalg.norm(a-b)\n",
    "dist2 = np.linalg.norm(a-c)\n",
    "print(dist1)\n",
    "print(dist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367491.3\n",
      "84754.97\n"
     ]
    }
   ],
   "source": [
    "print(((a - b) * (a - b)).sum())\n",
    "print(((a - c) * (a - c)).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 语谱图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "librosa.display.specshow(librosa.power_to_db(librosa.stft(y),ref=np.max), y_axis='mel', x_axis='time')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Mel spectrogram')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 录音/保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 2\n",
    "RATE = 44100\n",
    "RECORD_SECONDS = 3  #设置录音的时间长度\n",
    "WAVE_OUTPUT_FILENAME = \"./voice/thinking5.wav\"\n",
    "p = pyaudio.PyAudio()\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "print(\"* recording\")\n",
    "frames = []\n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "print(\"* done recording\")\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画FFT图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import wave\n",
    "from scipy.fftpack import fft,ifft\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    " \n",
    "def data_fft(data, time, time_start, time_end):\n",
    "        #短时fft。截取一段时间内的数据先\n",
    "        #time_start是开始时间，time_end是结束时间\n",
    "        t = []\n",
    "        y = []\n",
    "        count = 0\n",
    "        #for i in time:\n",
    "        for i in range(time.size):\n",
    "                if((time[i] >= time_start) & (time[i] <= time_end)):\n",
    "                        count = count + 1\n",
    "                        t = np.append(t, time[i])\n",
    "                        y = np.append(y, data[0][i])    #只提取左声道\n",
    "        #print (count)\n",
    "                        \n",
    "        yy=fft(y)                  #快速傅里叶变换\n",
    "        yreal = yy.real               # 获取实数部分\n",
    "        yimag = yy.imag               # 获取虚数部分\n",
    " \n",
    "                \n",
    "        yf=abs(fft(y))                # 取绝对值\n",
    "        yf1=abs(fft(y))/len(t)           #归一化处理\n",
    "        yf2 = yf1[range(int(len(t)/2))]  #由于对称性，只取一半区间\n",
    " \n",
    "        xf = np.arange(len(y))        # 频率\n",
    "        xf1 = xf\n",
    "        xf2 = xf[range(int(len(t)/2))]  #取一半区间\n",
    " \n",
    "        #plt.figure()\n",
    "        \"\"\"\n",
    "        \n",
    "        plt.subplot(221)\n",
    "        plt.plot(t, y)   \n",
    "        plt.title('Original wave')\n",
    " \n",
    "        plt.subplot(222)\n",
    "        plt.plot(xf,yf,'r')\n",
    "        plt.title('FFT of Mixed wave(two sides frequency range)',fontsize=7,color='#7A378B')  #注意这里的颜色可以查询颜色代码表\n",
    " \n",
    "        plt.subplot(223)\n",
    "        plt.plot(xf1,yf1,'g')\n",
    "        plt.title('FFT of Mixed wave(normalization)',fontsize=9,color='r')\n",
    " \n",
    "        plt.subplot(224)\n",
    "        plt.plot(xf2,yf2,'b')\n",
    "        plt.title('FFT of Mixed wave)',fontsize=10,color='#F08080')\n",
    "        \n",
    "        \"\"\"\n",
    "        plt.plot(t, y)   \n",
    "        plt.title('Original wave')\n",
    " \n",
    " \n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "def main():\n",
    "\twave_data, time = read_wave_data('./voice/angry1.wav')\n",
    "\t\n",
    "\tdata_fft(wave_data, time, 0, 2)\n",
    "\t\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
